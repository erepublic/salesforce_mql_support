/* eslint-disable no-console */

const fs = require("node:fs");
const os = require("node:os");
const path = require("node:path");
const { execFileSync } = require("node:child_process");

function run(cmd, args, opts = {}) {
  return execFileSync(cmd, args, {
    encoding: "utf8",
    stdio: ["ignore", "pipe", "pipe"],
    ...opts
  });
}

function runSfJson(args) {
  const out = run("sf", args);
  return JSON.parse(out);
}

function sleep(ms) {
  Atomics.wait(new Int32Array(new SharedArrayBuffer(4)), 0, 0, ms);
}

function chunk(arr, n) {
  const out = [];
  for (let i = 0; i < arr.length; i += n) out.push(arr.slice(i, i + n));
  return out;
}

function safeInClause(ids) {
  const clean = (ids || []).filter(Boolean);
  if (!clean.length) return "(null)";
  return `(${clean.map((id) => `'${String(id).replaceAll("'", "\\'")}'`).join(",")})`;
}

function parseArgs(argv) {
  const args = {
    targetOrg: "mql-sandbox",
    batchSize: 5,
    sleepSeconds: 20,
    maxBatches: Infinity,
    noOpenOppsFirst: true
  };
  for (let i = 2; i < argv.length; i++) {
    const a = argv[i];
    if (a === "--target-org") args.targetOrg = String(argv[++i] || "").trim();
    else if (a === "--batch-size") args.batchSize = Number(argv[++i]);
    else if (a === "--sleep-seconds") args.sleepSeconds = Number(argv[++i]);
    else if (a === "--max-batches") args.maxBatches = Number(argv[++i]);
    else if (a === "--no-open-opps-first")
      args.noOpenOppsFirst = String(argv[++i] || "true") !== "false";
  }
  if (!args.targetOrg) throw new Error("invalid --target-org");
  if (!Number.isFinite(args.batchSize) || args.batchSize <= 0)
    throw new Error("invalid --batch-size");
  if (!Number.isFinite(args.sleepSeconds) || args.sleepSeconds < 0)
    throw new Error("invalid --sleep-seconds");
  if (
    args.maxBatches !== Infinity &&
    (!Number.isFinite(args.maxBatches) || args.maxBatches <= 0)
  ) {
    throw new Error("invalid --max-batches");
  }
  return args;
}

function main() {
  const { targetOrg, batchSize, sleepSeconds, maxBatches, noOpenOppsFirst } =
    parseArgs(process.argv);

  const res = runSfJson([
    "data",
    "query",
    "--target-org",
    targetOrg,
    "--query",
    "SELECT Id, CreatedDate, Contact__c, Opportunity__c FROM MQL__c ORDER BY CreatedDate DESC",
    "--json"
  ]);

  const records = res?.result?.records || [];
  let ids = records.map((r) => r.Id).filter(Boolean);

  if (noOpenOppsFirst) {
    const contactIds = Array.from(
      new Set(records.map((r) => r.Contact__c).filter(Boolean))
    );
    const openOppCountByContactId = new Map();
    try {
      for (const batch of chunk(contactIds, 200)) {
        const q = `SELECT ContactId contactId, COUNT(Id) cnt FROM OpportunityContactRole WHERE ContactId IN ${safeInClause(
          batch
        )} AND Opportunity.IsClosed = false GROUP BY ContactId`;
        const out = runSfJson([
          "data",
          "query",
          "--target-org",
          targetOrg,
          "--query",
          q,
          "--json"
        ]);
        const rows = out?.result?.records || [];
        for (const row of rows) {
          const cid = row?.contactId;
          const cnt = Number(row?.cnt || 0);
          if (cid) openOppCountByContactId.set(cid, cnt);
        }
      }
    } catch (e) {
      console.error(
        "Open opportunity lookup failed; falling back to CreatedDate ordering.",
        {
          message: e?.message
        }
      );
    }

    const sorted = [...records].sort((a, b) => {
      const aOpen = Number(openOppCountByContactId.get(a.Contact__c) || 0);
      const bOpen = Number(openOppCountByContactId.get(b.Contact__c) || 0);

      // Primary: no open opps first (0 before >0).
      if (aOpen === 0 && bOpen > 0) return -1;
      if (bOpen === 0 && aOpen > 0) return 1;

      // Secondary: MQL not explicitly tied to an Opportunity__c first (still keep deterministic).
      const aHasOpp = Boolean(a.Opportunity__c);
      const bHasOpp = Boolean(b.Opportunity__c);
      if (!aHasOpp && bHasOpp) return -1;
      if (!bHasOpp && aHasOpp) return 1;

      // Tertiary: newest-first.
      return Date.parse(b.CreatedDate) - Date.parse(a.CreatedDate);
    });

    ids = sorted.map((r) => r.Id).filter(Boolean);

    const numNoOpenOpp = sorted.filter(
      (r) => Number(openOppCountByContactId.get(r.Contact__c) || 0) === 0
    ).length;
    console.log(
      `Found ${ids.length} MQL__c records (${numNoOpenOpp} with openOppCount=0; enqueuing those first)`
    );
  } else {
    console.log(`Found ${ids.length} MQL__c records`);
  }

  const batches = chunk(ids, batchSize).slice(0, maxBatches);
  const tmpFile = path.join(os.tmpdir(), `mql_backfill_${Date.now()}.apex`);

  for (let idx = 0; idx < batches.length; idx++) {
    const batch = batches[idx];
    const setLiteral = batch.map((id) => `'${id}'`).join(", ");
    const apex = [
      "// Auto-generated by regenerate_mql_summaries_sandbox_sequential.js",
      `MqlSummarizerCallout.triggerSummarizationForce(new Set<Id>{ ${setLiteral} });`,
      ""
    ].join("\n");

    fs.writeFileSync(tmpFile, apex, "utf8");
    console.log(
      `Enqueuing batch ${idx + 1}/${batches.length} (size=${batch.length})`
    );

    try {
      run("sf", ["apex", "run", "--target-org", targetOrg, "--file", tmpFile], {
        stdio: ["ignore", "pipe", "pipe"]
      });
    } catch (e) {
      console.error("Batch enqueue failed", {
        idx: idx + 1,
        message: e?.message
      });
    }

    if (idx < batches.length - 1 && sleepSeconds > 0) {
      sleep(sleepSeconds * 1000);
    }
  }

  try {
    fs.unlinkSync(tmpFile);
  } catch {
    // ignore
  }

  console.log(
    "Done enqueuing batches. Summaries update asynchronously; rerun the check script in a few minutes."
  );
}

main();
